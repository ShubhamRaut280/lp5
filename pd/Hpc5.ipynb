{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment No. 5\n",
        "***Title:  Implement HPC application for AI/ML domain.***"
      ],
      "metadata": {
        "id": "40ijgOp8-Tlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UdCGAn4NUEG",
        "outputId": "27b4dc56-395e-4cd5-cd6a-5b79fb4f12f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.3.tar.gz (466 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/466.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.3/466.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl size=4458268 sha256=7b75e58544a563e8609a6b8d08f17d2e3f35fdeebc614b7b196de08866d2c0ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/56/17/bf6ba37aa971a191a8b9eaa188bf5ec855b8911c1c56fb1f84\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MQ22Fj0LnXd",
        "outputId": "5f98d811-1daa-4eef-d8e2-d81c8073d833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train accuracy = 0.9756, Test accuracy = 0.9725\n",
            "Epoch 2: Train accuracy = 0.9845, Test accuracy = 0.9797\n",
            "Epoch 3: Train accuracy = 0.9872, Test accuracy = 0.9790\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "\n",
        "# Initialize MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "# Load and preprocess dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
        "\n",
        "# Build the model\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Training function (distributed)\n",
        "def train(model, x_train, y_train, rank, size):\n",
        "    # Split data across nodes\n",
        "    n = len(x_train)\n",
        "    chunk_size = n // size\n",
        "    start = rank * chunk_size\n",
        "    end = n if rank == size - 1 else (rank + 1) * chunk_size\n",
        "\n",
        "    x_train_chunk = x_train[start:end]\n",
        "    y_train_chunk = y_train[start:end]\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    model.fit(x_train_chunk, y_train_chunk, epochs=1, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate\n",
        "    train_loss, train_acc = model.evaluate(x_train_chunk, y_train_chunk, verbose=0)\n",
        "\n",
        "    # Average accuracy across all processes\n",
        "    train_acc = comm.allreduce(train_acc, op=MPI.SUM) / size\n",
        "    return train_acc\n",
        "\n",
        "# Create and train model\n",
        "model = create_model()\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Train on local chunk\n",
        "    train_acc = train(model, x_train, y_train, rank, size)\n",
        "\n",
        "    # Evaluate on full test set\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    test_acc = comm.allreduce(test_acc, op=MPI.SUM) / size\n",
        "\n",
        "    # Output results\n",
        "    if rank == 0:\n",
        "        print(f\"Epoch {epoch + 1}: Train accuracy = {train_acc:.4f}, Test accuracy = {test_acc:.4f}\")\n"
      ]
    }
  ]
}